{
 "metadata": {
  "name": "Classification_and_Regression"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "This notebook is an adaptation of Jake Vanderplas' tutorial on scikit-learn, published on Mar 14, 2013.  "
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Machine Learning with scikit-learn"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Machine learning is about creating models from data: for that reason, we'll start by\ndiscussing how data can be represented in order to be understood by the computer.  \n\nBy the end of this section you should:\n\n- Know the internal data representation of scikit-learn.\n- Know how to use scikit-learn's methods to do supervised classification and regression.\n\n\n**You can press ``Ctrl-m h`` for a list of all ipython keyboard shortcuts.\nUse ``tab`` for Auto-fill**"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Data in scikit-learn"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Data in scikit-learn, with very few exceptions, is assumed to be stored as a\n**two-dimensional array**, of size `[n_samples, n_features]`."
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Most machine learning algorithms implemented in scikit-learn expect data to be stored in a\n**two-dimensional array or matrix**.  The arrays can be\neither ``numpy`` arrays, or in some cases ``scipy.sparse`` matrices.\nThe size of the array is expected to be `[n_samples, n_features]`\n\n- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n  A sample can be a document, a person, a sound, a video, an astronomical object,\n  a column in database or CSV file,\n  or whatever you can describe with a fixed set of quantitative traits.\n- **n_features:**  The number of features or distinct traits that can be used to describe each\n  item in a quantitative manner.  Features are generally real-valued, but may be boolean or\ndiscrete or continuous-valued in some cases. Eg, various criteria to describe a company (P/E ratio, Market Cap, Growth Rate), criteria to describe a patient (Gene Expression Values in a tissue, age, medication, metabolic parameters, etc.)\n\nThe number of features must be fixed in advance. However it can be very high dimensional\n(e.g. millions of features) with most of them being zeros for a given sample. This is a case\nwhere `scipy.sparse` matrices can be useful, in that they are\nmuch more memory-efficient than numpy arrays."
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "A Simple Example: the Iris Dataset"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "As an example of a simple dataset, we're going to take a look at the iris data stored by scikit-learn.\nThe data consists of measurements of three different species of irises.  There are three species of iris\nin the dataset, which we can picture here:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import os\nprint os.getcwd()\n\n# set to your currect directory\nos.chdir('C:\\Users\\Dong Yu\\Desktop\\ML_Lectures') \nfrom IPython.core.display import Image, display\ndisplay(Image(filename='iris_setosa.jpg'))\nprint \"Iris Setosa\\n\"\n\ndisplay(Image(filename='iris_versicolor.jpg'))\nprint \"Iris Versicolor\\n\"\n\ndisplay(Image(filename='iris_virginica.jpg'))\nprint \"Iris Virginica\"",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Loading the Iris Data with Scikit-learn"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Scikit-learn has a very straightforward set of data on these iris species.  The data consist of\nthe following:\n\n- Features in the Iris dataset:\n\n  1. sepal length in cm\n  2. sepal width in cm\n  3. petal length in cm\n  4. petal width in cm\n\n- Samples in the Iris dataset:\n    Values of above features in 150 flowers. (flower=sample)\n\n\n- Target classes to predict:\n\n  1. Iris Setosa\n  2. Iris Versicolour\n  3. Iris Virginica"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "``scikit-learn`` embeds a copy of the iris CSV file along with a helper function to load it into numpy arrays:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.datasets import load_iris\niris = load_iris()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The resulting dataset is a ``Bunch`` object: you can see what's available using\nthe method ``keys()``:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "iris.keys()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The features of each sample flower are stored in the ``data`` attribute of the dataset:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "n_samples, n_features = iris.data.shape\nprint \"# of samples = \", n_samples\nprint \"# of features = \", n_features\nprint \"Iris data looks like this:\"\nprint iris.data[0:5]",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The information about the class of each sample is stored in the ``target`` attribute of the dataset:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print iris.data.shape\nprint iris.target.shape",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print iris.target",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The names of the classes are stored in the last attribute, namely ``target_names``:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print iris.target_names",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "This data is four dimensional, but we can visualize two of the dimensions\nat a time using a simple scatter-plot.  Again, we'll start by enabling\npylab inline mode:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# note: this also imports numpy as np, imports matplotlib.pyplot as plt, and others\n%pylab inline",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "x_index = 1\ny_index = 3\n\n# this formatter will label the colorbar with the correct target names\nformatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n\nplt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target)\nplt.colorbar(ticks=[0, 1, 2], format=formatter)\nplt.xlabel(iris.feature_names[x_index])\nplt.ylabel(iris.feature_names[y_index])",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Quick Exercise:"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**Change** `x_index` **and** `y_index` **in the above script\nand find a combination of two parameters\nwhich maximally separate the three classes. The features that separate the \nthree classes most distinctively would be having most variance, \nor highest information content.**\n\nThis exercise is a preview of **dimensionality reduction**, which we'll see later. "
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Supervised Learning: Classification of Iris Data"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "By the end of this section you will\n\n- Know how to instantiate a scikit-learn classifier\n- Know how to train a classifier by calling the `fit(...)` method\n- Know how to predict new labels by calling the `predict(...)` method\n\nIn this example we will perform classification of the iris data with several different classifiers."
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Linear Support Vector Classifier (SVC)"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "First we'll load the iris data as we did before:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.datasets import load_iris\niris = load_iris()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "In the iris dataset example, suppose we are assigned the task to guess\nthe class of an individual flower given the measurements of petals and\nsepals. This is a *classification* task, hence we have:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "X = iris.data\ny = iris.target\n\nprint X.shape\nprint y.shape",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Once the data has this format it is trivial to train a classifier, for instance a support vector machine with a linear kernel:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.svm import LinearSVC",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "LinearSVC is an example of a scikit-learn classifier. If you're curious about how it is used, you can use ipython's \"?\" magic function to see the documentation:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print y",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The first thing to do is to create an instance of the classifier.  This can be done simply by calling the class name, with any arguments that the object accepts:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = LinearSVC(loss = 'l2')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "``clf`` is a statistical model that has parameters that control the learning algorithm (those parameters are sometimes called the *hyperparameters*). Those hyperparameters can be supplied by the user in the constructor of the model. We will explain later how to choose a good combination using either simple empirical rules or data driven selection:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print clf",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "By default the model parameters are not initialized. They will be tuned automatically from the data by calling the fit method with the data X and labels y:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf = clf.fit(X, y)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "We can now see some of the fit parameters within the classifier object.\n\n**In scikit-learn, parameters defined by training have a trailing underscore.**"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf.coef_",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "clf.intercept_",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Once the model is trained, it can be used to predict the most likely outcome on unseen data. For instance let us define a list of simple sample that looks like the first sample of the iris dataset:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "X_new = [[ 5.0,  3.6,  1.3,  0.25]]\n\nprint clf.predict(X_new) # predict the class for X_new\n\nnew_Y = clf.predict(X)  # predict the class for all elements of X\n\n# calculating accuracy\naccuracy = 0\nfor i in range(len(new_Y)):\n    if new_Y[i]==y[i]:\n        accuracy+=1\n\nprint accuracy*100/float(len(new_Y))\n\nnew_Y == y",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "All classification tasks involve predicting an unknown category based on observed features.\n\nSome examples of interested classification tasks:\n\n- **E-mail classification:** label email as spam, normal, priority mail\n- **Language identification:** label documents as English, Spanish, German, etc.\n- **News articles categorization:** label articles as business, technology, sports...\n- **Sentiment analysis in customer feedback:** label feedback as negative, neutral, positive\n- **Medicine:** Classify patient as likely to suffer from a disease or not based on genetic and metabolic variables/factors."
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": ""
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Supervised Learning: Regression of Housing Data"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "\nBy the end of this section you will\n\n- Know how to instantiate a scikit-learn regression model\n- Know how to train a regressor by calling the `fit(...)` method\n- Know how to predict new labels by calling the `predict(...)` method\n\nHere we'll do a short example of a regression problem: learning a continuous value\nfrom a set of features.\n\nWe'll use the simple Boston house prices set, available in scikit-learn.  This\nrecords measurements of 13 attributes of housing markets around Boston, as well\nas the median price.  The question is: can you predict the price of a new\nmarket given its attributes?\n\nFirst we'll load the dataset:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn import datasets",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "data = datasets.load_boston()\n\nprint data.keys()\n\nprint data.data.shape\n\nprint data.DESCR\n\nprint data.target.shape",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "It often helps to quickly visualize pieces of the data using histograms, scatter plots, or other plot types. Here we'll load pylab and show a histogram of the target values: the median price in each neighborhood."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%pylab inline",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "plt.hist(data.target)\nplt.xlabel('price ($1000s)')\nplt.ylabel('count')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "i=0  # vary i from 0 to 12\n\nprint data.feature_names[i]\n\nfeature = data.data[:,i]\n\nplt.hist(feature)\nplt.xlabel(data.feature_names[i])\nplt.ylabel('count')\n\nlabel =  data.target  # price is just a continuous label \n\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.plot(feature, label, 'o')\nax.set_xlabel(data.feature_names[i])\nax.set_ylabel('Price')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Predicting Home Prices: a Simple Linear Regression"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Now we'll use scikit-learn to perform a simple linear regression on the housing data. There are many possibilities of regressors to use. A particularly simple one is LinearRegression: this is basically a wrapper around an ordinary least squares calculation.\n\n\nWe'll set it up like this:"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.linear_model import LinearRegression\n\nclf = LinearRegression()\n\nclf.fit(data.data, data.target)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "predicted = clf.predict(data.data)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "plt.scatter(data.target, predicted)\nplt.plot([0, 50], [0, 50], '--k')\nplt.axis('tight')\nplt.xlabel('True price ($1000s)')\nplt.ylabel('Predicted price ($1000s)')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The prediction at least correlates with the true price, though there are clearly some biases. "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print '# of samples = ', len(predicted)\nsum = 0\nfor i in range(len(predicted)):\n    sum+=((predicted[i]-data.target[i])**2)\nrmse = math.sqrt(sum/len(predicted))\nprint 'RMS error = ', rmse\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print \"RMS error = %.4g\" % np.sqrt(np.mean((predicted - data.target) ** 2))",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "There are many examples of regression-type problems in machine learning\n\n- **Sales:** given consumer data, predict how much they will spend\n- **Advertising:** given information about a user, predict the click-through rate for a web ad.\n- **Collaborative Filtering:** given a collection of user-ratings for movies, predict preferences for other movies & users\n- **Medicine:** given observations of metabolic biomarkers, predict disease state.   \n\nAnd much, much more.\n\n\nWe can evaluate the performance of the regressor by computing the RMS residuals between the true and predicted price. However, in the above example, ``the prediction is done on data points using which the model is trained`` ('line is fitted to'). \n"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "**Question:** what might be the problem with this approach?"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}